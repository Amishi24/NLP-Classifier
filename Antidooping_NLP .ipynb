{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0358b6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "400904ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Testimony</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Suspicious Behavior at Gym</td>\n",
       "      <td>I noticed an athlete injecting themselves with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Supplier Name in Conversation</td>\n",
       "      <td>I overheard a conversation where two athletes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Package Exchange at Competition</td>\n",
       "      <td>During a recent competition, I saw a coach han...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unusual Medical Treatment</td>\n",
       "      <td>One athlete I train with regularly has been vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bulk Purchase of Supplements</td>\n",
       "      <td>I work at a store that sells supplements, and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Title  \\\n",
       "0       Suspicious Behavior at Gym   \n",
       "1    Supplier Name in Conversation   \n",
       "2  Package Exchange at Competition   \n",
       "3        Unusual Medical Treatment   \n",
       "4     Bulk Purchase of Supplements   \n",
       "\n",
       "                                           Testimony  \n",
       "0  I noticed an athlete injecting themselves with...  \n",
       "1  I overheard a conversation where two athletes ...  \n",
       "2  During a recent competition, I saw a coach han...  \n",
       "3  One athlete I train with regularly has been vi...  \n",
       "4  I work at a store that sells supplements, and ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('/Users/amishi/Downloads/anti_doping_testimonies.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "538f9855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d55f77b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "data['Label'] = label_encoder.fit_transform(data['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38567a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    data['Testimony'], data['Label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e1ddea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amishi/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ccb1a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bb79c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Preparation\n",
    "class TestimonyDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts.iloc[idx]\n",
    "        label = self.labels.iloc[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text, truncation=True, padding=\"max_length\", max_length=self.max_len, return_tensors=\"pt\"\n",
    "        )\n",
    "        return {key: val.squeeze(0) for key, val in encoding.items()}, torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5ccc9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Datasets\n",
    "train_dataset = TestimonyDataset(train_texts, train_labels, tokenizer)\n",
    "test_dataset = TestimonyDataset(test_texts, test_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c536330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06a2e7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6df9bdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/amishi/anaconda3/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Model Initialization\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=len(data['Label'].unique()))\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79d50044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25042534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.07066068850527517\n",
      "Epoch 2, Loss: 0.000572715820162557\n",
      "Epoch 3, Loss: 0.0001755527284258278\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):  # Number of epochs\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        inputs, labels = batch\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b54b0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6377e96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Loop\n",
    "model.eval()\n",
    "predictions, true_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs, labels = batch\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predictions.extend(torch.argmax(logits, axis=-1).cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "753e8729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "   Bulk Purchase of Supplements       1.00      1.00      1.00       189\n",
      "     Hidden Documents in Locker       1.00      1.00      1.00       183\n",
      "Package Exchange at Competition       1.00      1.00      1.00       212\n",
      "           Private Lab Sessions       1.00      1.00      1.00       196\n",
      "    Rapid Recovery After Injury       1.00      1.00      1.00       195\n",
      "     Strange Deliveries at Home       1.00      1.00      1.00       204\n",
      "  Supplier Name in Conversation       1.00      1.00      1.00       195\n",
      "     Suspicious Behavior at Gym       1.00      1.00      1.00       219\n",
      "    Unofficial Training Regimen       1.00      1.00      1.00       189\n",
      "      Unusual Medical Treatment       1.00      1.00      1.00       218\n",
      "\n",
      "                       accuracy                           1.00      2000\n",
      "                      macro avg       1.00      1.00      1.00      2000\n",
      "                   weighted avg       1.00      1.00      1.00      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(true_labels, predictions, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce33c015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a060c1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model/fine_tuned_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f323930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
